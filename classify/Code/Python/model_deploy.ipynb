{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: paho-mqtt in /home/ubie/.local/lib/python3.10/site-packages (2.1.0)\n",
      "Requirement already satisfied: scipy in /home/ubie/.local/lib/python3.10/site-packages (1.14.1)\n",
      "Requirement already satisfied: numpy<2.3,>=1.23.5 in /home/ubie/.local/lib/python3.10/site-packages (from scipy) (2.0.2)\n"
     ]
    }
   ],
   "source": [
    "! pip install paho-mqtt scipy\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import paho.mqtt.client as mqtt\n",
    "from Functions import Data_path, Plot_data ,CCA, ROC\n",
    "from Functions.Filtering import filtering\n",
    "from Functions.Common_average_reference import car \n",
    "from Functions.CCA_Feature_Extraction import cca_feature_extraction\n",
    "# from Functions.CCA_FE_Single_Trial import cca_feature_extraction\n",
    "from Functions.Feature_selections import feature_selecions \n",
    "\n",
    "import sys\n",
    "np.set_printoptions(threshold=sys.maxsize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_values(arr):\n",
    "    \"\"\"\n",
    "    Function to count occurrences of 0s, 1s, and 2s in a given array.\n",
    "    \n",
    "    Parameters:\n",
    "    arr (list): The input array containing numbers.\n",
    "    \n",
    "    Returns:\n",
    "    tuple: A tuple containing the count of 0s, 1s, and 2s in the array.\n",
    "    \"\"\"\n",
    "    count_zeros = np.count_nonzero(arr == 0)\n",
    "    count_ones = np.count_nonzero(arr == 1)\n",
    "    count_twos = np.count_nonzero(arr == 2)\n",
    "        \n",
    "    return count_zeros, count_ones, count_twos\n",
    "\n",
    "\n",
    "saved_model = joblib.load(\"trained_model.pkl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Initialize parameters and system\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "order = 4\n",
    "notch_freq = 50\n",
    "quality_factor = 20\n",
    "subbands = [[12, 16, 20], [14, 18, 22]]\n",
    "f_low = np.min(subbands) - 1\n",
    "f_high = np.max(subbands) + 1\n",
    "notch_filter = \"on\"\n",
    "filter_active = \"on\"\n",
    "type_filter = \"bandpass\"\n",
    "num_harmonic = 4\n",
    "f_stim = [13, 21, 17]\n",
    "num_channel = [0, 1]\n",
    "window_size = 256  # Example window size\n",
    "overlap = 128      # Example overlap size\n",
    "fs = 256           # Sampling frequency\n",
    "\n",
    "\n",
    "\n",
    "###############     CCA     ################\n",
    "num_harmonic = 4          # Number of harmonic for each frequency stimulation\n",
    "f_stim = [13, 21, 17]     # Frequencies stimulation\n",
    "num_channel = [0, 1]      # Number of Channel     \n",
    "\n",
    "\n",
    "\n",
    "############### feature selection ###########\n",
    "num_features = 24                  # pick any random high number it's result won't go beyond its limits :)\n",
    "type_feature_selection = \"anova\"   # var, anova, mi, ufs, rfe, rf, l1fs, tfs, fs, ffs, bfs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Define a function to process data chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_chunk(data_chunk):\n",
    "    # Apply filtering\n",
    "    filtered_chunk = filtering(data_chunk, f_low, f_high, order, fs, notch_freq, quality_factor, filter_active, notch_filter, type_filter)\n",
    "    # Apply CAR\n",
    "    car_chunk = car(filtered_chunk)\n",
    "    # Extract features using CCA\n",
    "    features_chunk = cca_feature_extraction(car_chunk, fs, f_stim, num_channel, num_harmonic)\n",
    "    return features_chunk\n",
    "\n",
    "# Example usage during inference\n",
    "def normalize_inference(x_real_time, scaler_filename=\"normalize.joblib\"):\n",
    "    # Load the saved scaler\n",
    "    norm = joblib.load(scaler_filename)\n",
    "    \n",
    "    if x_real_time.ndim == 1:\n",
    "        x_real_time = x_real_time.reshape(-1, 1)\n",
    "    \n",
    "    x_real_time_normalized = norm.transform(x_real_time)\n",
    "    \n",
    "    return x_real_time_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Simulate real-time data streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_time_processing(streaming_data):\n",
    "    num_samples = streaming_data.shape[0]\n",
    "    start_idx = 0\n",
    "    while start_idx < num_samples:\n",
    "        end_idx = min(start_idx + window_size, num_samples)\n",
    "        data_chunk = streaming_data[start_idx:end_idx, :, :]\n",
    "        \n",
    "        if data_chunk.shape[0] == window_size:\n",
    "            features_chunk = process_data_chunk(data_chunk)\n",
    "            print(\"Processed chunk features:\", features_chunk.shape)\n",
    "            # Here you can do further processing or classification with features_chunk\n",
    "        start_idx += (window_size - overlap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 : Data acquisition using MQTT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_179646/1913016128.py:5: DeprecationWarning: Callback API version 1 is deprecated, update to latest version\n",
      "  client = mqtt.Client()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MQTT broker with result code: 0\n",
      "Received EEG data for frequency 13Hz\n",
      "EEG data shape: (1280, 8, 1)\n",
      "CAR data :  (1280, 8, 1)\n",
      "Extracted feature :  (1, 6)\n",
      "Error processing message: Found array with dim 3. MinMaxScaler expected <= 2.\n"
     ]
    }
   ],
   "source": [
    "import json \n",
    "MQTT_BROKER = \"localhost\"\n",
    "MQTT_PORT = 1883\n",
    "MQTT_TOPIC = \"DAQ\"\n",
    "client = mqtt.Client()\n",
    "saved_model = joblib.load(\"trained_model.pkl\")\n",
    "\n",
    "\n",
    "def on_connect(client, userdata, flags, rc):\n",
    "    print(f\"Connected to MQTT broker with result code: {rc}\")\n",
    "    client.subscribe(MQTT_TOPIC)  # Subscribe to a topic if needed\n",
    "\n",
    "def on_message(client, userdata, msg):\n",
    "    try:\n",
    "        message = json.loads(msg.payload.decode())\n",
    "\n",
    "        frequency = message['frequency']\n",
    "        \n",
    "        eeg_data_list = message['eeg_data']\n",
    "        eeg_data = np.array(eeg_data_list)\n",
    "\n",
    "        print(f\"Received EEG data for frequency {frequency}\")\n",
    "        print(f\"EEG data shape: {eeg_data.shape}\")\n",
    "        # print(f\"EEG data : {eeg_data}\")\n",
    "\n",
    "        filtered_data = filtering(eeg_data, f_low, f_high, order, fs, notch_freq, quality_factor, \n",
    "                                    filter_active, notch_filter, type_filter)\n",
    "        \n",
    "        data_car = car(filtered_data) \n",
    "        print('CAR data : ', data_car.shape)\n",
    "\n",
    "# For total data (1280,8,480) -> features will be (480,6) for two channels\n",
    "        features_extraction = cca_feature_extraction(data_car, fs, f_stim, num_channel, num_harmonic)\n",
    "        print(\"Extracted feature : \",features_extraction.shape)\n",
    "\n",
    "        #normalization\n",
    "        norm_features = normalize_inference(features_extraction)\n",
    "\n",
    "        # result\n",
    "        feature_output = saved_model.predict(norm_features)\n",
    "        z1,o1,t1 = count_values(feature_output)\n",
    "\n",
    "        print(f\"predicted result = {feature_output}\")\n",
    "        print(f\"Result : Zeros: {z1}, Ones: {o1}, Twos: {t1}\")\n",
    "\n",
    "        # mapping with commands\n",
    "        mapping = { 0 : \"0\", 1 : \"1\" , 2 : \"2\"}\n",
    "        print(mapping[ 0 if z1 > o1 and z1 > t1 else 1 if o1 > t1 else 2])\n",
    "\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing message: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "def connect_mqtt():\n",
    "    client.on_connect = on_connect\n",
    "    client.on_message = on_message\n",
    "    client.connect(MQTT_BROKER, MQTT_PORT, 60)\n",
    "    client.loop_start()  # Start the MQTT client loop in a separate thread\n",
    "\n",
    "# Initialize MQTT client and connect\n",
    "connect_mqtt()\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        pass  # Keep the main thread alive to process MQTT messages\n",
    "except KeyboardInterrupt:\n",
    "    client.loop_stop()\n",
    "    client.disconnect()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
